{
    "function": "average",
    "asm": [
        {
            "type": [
                "float",
                "float"
            ],
            "instr": [
                "vmovaps 0x0(%rip),%ymm2",
                "vmulps %ymm2,%ymm1,%ymm1",
                "vmulps %ymm2,%ymm0,%ymm0",
                "vaddps %ymm1,%ymm0,%ymm0"
            ]
        },
        {
            "type": [
                "signed char",
                "signed char"
            ],
            "instr": [
                "push %rbp",
                "push %r15",
                "push %r14",
                "push %r13",
                "push %r12",
                "push %rbx",
                "vxorps %ymm0,%ymm1,%ymm3",
                "vpextrq $0x1,%xmm3,%rsi",
                "vextractf128 $0x1,%ymm3,%xmm15",
                "vmovq %xmm15,%rcx",
                "vpextrq $0x1,%xmm15,%r12",
                "vmovq %xmm3,%rdi",
                "vpshufb 0x0(%rip),%xmm3,%xmm4",
                "mov %edi,%edx",
                "shl $0x8,%edx",
                "vpinsrd $0x2,%edx,%xmm4,%xmm4",
                "vpinsrd $0x3,%edi,%xmm4,%xmm2",
                "vmovdqa %xmm2,-0x18(%rsp)",
                "mov %rsi,%r8",
                "mov %rcx,%r9",
                "shld $0x30,%rsi,%r9",
                "mov %rcx,%r10",
                "shld $0x28,%rsi,%r10",
                "mov %rsi,%r11",
                "shld $0x30,%rdi,%r11",
                "mov %rsi,%rbx",
                "shld $0x28,%rdi,%rbx",
                "mov %rsi,%r13",
                "mov %esi,%ebp",
                "mov %rcx,%r14",
                "shld $0x10,%rsi,%r14",
                "mov %rcx,%r15",
                "shld $0x8,%rsi,%r15",
                "mov %rsi,%rax",
                "shld $0x10,%rdi,%rax",
                "shld $0x8,%rdi,%rsi",
                "vmovq %rbx,%xmm4",
                "mov %rdi,%rbx",
                "shr $0x8,%rbx",
                "vmovq %r11,%xmm5",
                "vpunpckldq %xmm4,%xmm5,%xmm4",
                "vpextrd $0x1,%xmm3,%r11d",
                "vpshufd $0x50,%xmm4,%xmm4",
                "vmovd %ebx,%xmm5",
                "vpblendw $0x3,%xmm5,%xmm4,%xmm4",
                "vpinsrd $0x3,%r11d,%xmm4,%xmm2",
                "vmovdqa %xmm2,-0x28(%rsp)",
                "mov %r12d,%edx",
                "shl $0x18,%edx",
                "mov %rcx,%rbx",
                "shr $0x28,%rbx",
                "or %edx,%ebx",
                "mov %ecx,%edx",
                "shl $0x18,%edx",
                "shr $0x28,%r13",
                "or %edx,%r13d",
                "shl $0x18,%ebp",
                "shr $0x28,%rdi",
                "or %ebp,%edi",
                "vmovq %rsi,%xmm4",
                "vmovq %rax,%xmm6",
                "vpunpckldq %xmm4,%xmm6,%xmm4",
                "vmovd %edi,%xmm6",
                "vpextrd $0x2,%xmm3,%eax",
                "vpshufd $0x50,%xmm4,%xmm4",
                "vpblendw $0x3,%xmm6,%xmm4,%xmm4",
                "vpinsrd $0x3,%eax,%xmm4,%xmm10",
                "vmovq %r10,%xmm11",
                "vmovq %r9,%xmm12",
                "mov %r12,%rsi",
                "shr $0x8,%r8",
                "vmovq %r15,%xmm5",
                "mov %r12,%rax",
                "vmovq %r14,%xmm6",
                "mov %r12,%rdx",
                "vpunpckldq %xmm5,%xmm6,%xmm5",
                "vmovd %r13d,%xmm6",
                "vmovd %xmm15,%edi",
                "vpshufd $0x50,%xmm5,%xmm5",
                "vpblendw $0x3,%xmm6,%xmm5,%xmm5",
                "vpinsrd $0x3,%edi,%xmm5,%xmm13",
                "mov %r12,%rdi",
                "shld $0x30,%rcx,%rdi",
                "vmovd %r8d,%xmm14",
                "mov %r12,%rbp",
                "shld $0x28,%rcx,%rbp",
                "vmovq %rbp,%xmm7",
                "mov %r12,%rbp",
                "shld $0x10,%rcx,%rbp",
                "shld $0x8,%rcx,%r12",
                "vmovq %rdi,%xmm4",
                "shr $0x8,%rcx",
                "vpunpckldq %xmm7,%xmm4,%xmm4",
                "vmovd %ecx,%xmm7",
                "vpextrd $0x1,%xmm15,%ecx",
                "vpshufd $0x50,%xmm4,%xmm4",
                "vpblendw $0x3,%xmm7,%xmm4,%xmm4",
                "vpinsrd $0x3,%ecx,%xmm4,%xmm9",
                "vmovq %r12,%xmm7",
                "vmovq %rbp,%xmm5",
                "vpunpckldq %xmm7,%xmm5,%xmm5",
                "vmovd %ebx,%xmm7",
                "vpextrd $0x2,%xmm15,%ecx",
                "vpshufd $0x50,%xmm5,%xmm5",
                "vpblendw $0x3,%xmm7,%xmm5,%xmm5",
                "vpinsrd $0x3,%ecx,%xmm5,%xmm8",
                "shr $0x18,%rdx",
                "vmovq %rdx,%xmm7",
                "shr $0x10,%rax",
                "vmovq %rax,%xmm6",
                "shr $0x8,%rsi",
                "vmovd %esi,%xmm2",
                "vandps %ymm0,%ymm1,%ymm0",
                "vmovdqa -0x18(%rsp),%xmm1",
                "vpsrad $0x19,%xmm1,%xmm1",
                "vmovdqa -0x28(%rsp),%xmm4",
                "vpsrad $0x19,%xmm4,%xmm4",
                "vpackssdw %xmm4,%xmm1,%xmm1",
                "vpunpckldq %xmm11,%xmm12,%xmm4",
                "vpshufd $0x50,%xmm4,%xmm4",
                "vpblendw $0x3,%xmm14,%xmm4,%xmm4",
                "vpblendw $0xc0,%xmm3,%xmm4,%xmm3",
                "vpsrad $0x19,%xmm13,%xmm4",
                "vpsrad $0x19,%xmm9,%xmm5",
                "vpackssdw %xmm5,%xmm4,%xmm4",
                "vpunpckldq %xmm7,%xmm6,%xmm5",
                "vpsrad $0x19,%xmm10,%xmm6",
                "vpsrad $0x19,%xmm3,%xmm3",
                "vpsrad $0x19,%xmm8,%xmm7",
                "vpshufd $0x50,%xmm5,%xmm5",
                "vpblendw $0x3,%xmm2,%xmm5,%xmm2",
                "vpblendw $0xc0,%xmm15,%xmm2,%xmm2",
                "vpsrad $0x19,%xmm2,%xmm2",
                "vpackssdw %xmm2,%xmm7,%xmm2",
                "vpacksswb %xmm2,%xmm4,%xmm2",
                "vpackssdw %xmm6,%xmm6,%xmm4",
                "vpacksswb %xmm4,%xmm1,%xmm1",
                "vpshufb 0x0(%rip),%xmm3,%xmm3",
                "vpblendw $0xc0,%xmm3,%xmm1,%xmm1",
                "vextractf128 $0x1,%ymm0,%xmm3",
                "vpaddb %xmm3,%xmm2,%xmm2",
                "vpaddb %xmm0,%xmm1,%xmm0",
                "vinsertf128 $0x1,%xmm2,%ymm0,%ymm0",
                "pop %rbx",
                "pop %r12",
                "pop %r13",
                "pop %r14",
                "pop %r15",
                "pop %rbp"
            ]
        },
        {
            "type": [
                "char",
                "char"
            ],
            "instr": [
                "push %rbp",
                "push %r15",
                "push %r14",
                "push %r13",
                "push %r12",
                "push %rbx",
                "vxorps %ymm0,%ymm1,%ymm3",
                "vpextrq $0x1,%xmm3,%rsi",
                "vextractf128 $0x1,%ymm3,%xmm15",
                "vmovq %xmm15,%rcx",
                "vpextrq $0x1,%xmm15,%r12",
                "vmovq %xmm3,%rdi",
                "vpshufb 0x0(%rip),%xmm3,%xmm4",
                "mov %edi,%edx",
                "shl $0x8,%edx",
                "vpinsrd $0x2,%edx,%xmm4,%xmm4",
                "vpinsrd $0x3,%edi,%xmm4,%xmm2",
                "vmovdqa %xmm2,-0x18(%rsp)",
                "mov %rsi,%r8",
                "mov %rcx,%r9",
                "shld $0x30,%rsi,%r9",
                "mov %rcx,%r10",
                "shld $0x28,%rsi,%r10",
                "mov %rsi,%r11",
                "shld $0x30,%rdi,%r11",
                "mov %rsi,%rbx",
                "shld $0x28,%rdi,%rbx",
                "mov %rsi,%r13",
                "mov %esi,%ebp",
                "mov %rcx,%r14",
                "shld $0x10,%rsi,%r14",
                "mov %rcx,%r15",
                "shld $0x8,%rsi,%r15",
                "mov %rsi,%rax",
                "shld $0x10,%rdi,%rax",
                "shld $0x8,%rdi,%rsi",
                "vmovq %rbx,%xmm4",
                "mov %rdi,%rbx",
                "shr $0x8,%rbx",
                "vmovq %r11,%xmm5",
                "vpunpckldq %xmm4,%xmm5,%xmm4",
                "vpextrd $0x1,%xmm3,%r11d",
                "vpshufd $0x50,%xmm4,%xmm4",
                "vmovd %ebx,%xmm5",
                "vpblendw $0x3,%xmm5,%xmm4,%xmm4",
                "vpinsrd $0x3,%r11d,%xmm4,%xmm2",
                "vmovdqa %xmm2,-0x28(%rsp)",
                "mov %r12d,%edx",
                "shl $0x18,%edx",
                "mov %rcx,%rbx",
                "shr $0x28,%rbx",
                "or %edx,%ebx",
                "mov %ecx,%edx",
                "shl $0x18,%edx",
                "shr $0x28,%r13",
                "or %edx,%r13d",
                "shl $0x18,%ebp",
                "shr $0x28,%rdi",
                "or %ebp,%edi",
                "vmovq %rsi,%xmm4",
                "vmovq %rax,%xmm6",
                "vpunpckldq %xmm4,%xmm6,%xmm4",
                "vmovd %edi,%xmm6",
                "vpextrd $0x2,%xmm3,%eax",
                "vpshufd $0x50,%xmm4,%xmm4",
                "vpblendw $0x3,%xmm6,%xmm4,%xmm4",
                "vpinsrd $0x3,%eax,%xmm4,%xmm10",
                "vmovq %r10,%xmm11",
                "vmovq %r9,%xmm12",
                "mov %r12,%rsi",
                "shr $0x8,%r8",
                "vmovq %r15,%xmm5",
                "mov %r12,%rax",
                "vmovq %r14,%xmm6",
                "mov %r12,%rdx",
                "vpunpckldq %xmm5,%xmm6,%xmm5",
                "vmovd %r13d,%xmm6",
                "vmovd %xmm15,%edi",
                "vpshufd $0x50,%xmm5,%xmm5",
                "vpblendw $0x3,%xmm6,%xmm5,%xmm5",
                "vpinsrd $0x3,%edi,%xmm5,%xmm13",
                "mov %r12,%rdi",
                "shld $0x30,%rcx,%rdi",
                "vmovd %r8d,%xmm14",
                "mov %r12,%rbp",
                "shld $0x28,%rcx,%rbp",
                "vmovq %rbp,%xmm7",
                "mov %r12,%rbp",
                "shld $0x10,%rcx,%rbp",
                "shld $0x8,%rcx,%r12",
                "vmovq %rdi,%xmm4",
                "shr $0x8,%rcx",
                "vpunpckldq %xmm7,%xmm4,%xmm4",
                "vmovd %ecx,%xmm7",
                "vpextrd $0x1,%xmm15,%ecx",
                "vpshufd $0x50,%xmm4,%xmm4",
                "vpblendw $0x3,%xmm7,%xmm4,%xmm4",
                "vpinsrd $0x3,%ecx,%xmm4,%xmm9",
                "vmovq %r12,%xmm7",
                "vmovq %rbp,%xmm5",
                "vpunpckldq %xmm7,%xmm5,%xmm5",
                "vmovd %ebx,%xmm7",
                "vpextrd $0x2,%xmm15,%ecx",
                "vpshufd $0x50,%xmm5,%xmm5",
                "vpblendw $0x3,%xmm7,%xmm5,%xmm5",
                "vpinsrd $0x3,%ecx,%xmm5,%xmm8",
                "shr $0x18,%rdx",
                "vmovq %rdx,%xmm7",
                "shr $0x10,%rax",
                "vmovq %rax,%xmm6",
                "shr $0x8,%rsi",
                "vmovd %esi,%xmm2",
                "vandps %ymm0,%ymm1,%ymm0",
                "vmovdqa -0x18(%rsp),%xmm1",
                "vpsrad $0x19,%xmm1,%xmm1",
                "vmovdqa -0x28(%rsp),%xmm4",
                "vpsrad $0x19,%xmm4,%xmm4",
                "vpackssdw %xmm4,%xmm1,%xmm1",
                "vpunpckldq %xmm11,%xmm12,%xmm4",
                "vpshufd $0x50,%xmm4,%xmm4",
                "vpblendw $0x3,%xmm14,%xmm4,%xmm4",
                "vpblendw $0xc0,%xmm3,%xmm4,%xmm3",
                "vpsrad $0x19,%xmm13,%xmm4",
                "vpsrad $0x19,%xmm9,%xmm5",
                "vpackssdw %xmm5,%xmm4,%xmm4",
                "vpunpckldq %xmm7,%xmm6,%xmm5",
                "vpsrad $0x19,%xmm10,%xmm6",
                "vpsrad $0x19,%xmm3,%xmm3",
                "vpsrad $0x19,%xmm8,%xmm7",
                "vpshufd $0x50,%xmm5,%xmm5",
                "vpblendw $0x3,%xmm2,%xmm5,%xmm2",
                "vpblendw $0xc0,%xmm15,%xmm2,%xmm2",
                "vpsrad $0x19,%xmm2,%xmm2",
                "vpackssdw %xmm2,%xmm7,%xmm2",
                "vpacksswb %xmm2,%xmm4,%xmm2",
                "vpackssdw %xmm6,%xmm6,%xmm4",
                "vpacksswb %xmm4,%xmm1,%xmm1",
                "vpshufb 0x0(%rip),%xmm3,%xmm3",
                "vpblendw $0xc0,%xmm3,%xmm1,%xmm1",
                "vextractf128 $0x1,%ymm0,%xmm3",
                "vpaddb %xmm3,%xmm2,%xmm2",
                "vpaddb %xmm0,%xmm1,%xmm0",
                "vinsertf128 $0x1,%xmm2,%ymm0,%ymm0",
                "pop %rbx",
                "pop %r12",
                "pop %r13",
                "pop %r14",
                "pop %r15",
                "pop %rbp"
            ]
        },
        {
            "type": [
                "double",
                "double"
            ],
            "instr": [
                "vmovapd 0x0(%rip),%ymm2",
                "vmulpd %ymm2,%ymm1,%ymm1",
                "vmulpd %ymm2,%ymm0,%ymm0",
                "vaddpd %ymm1,%ymm0,%ymm0"
            ]
        },
        {
            "type": [
                "int",
                "int"
            ],
            "instr": [
                "vandps %ymm0,%ymm1,%ymm2",
                "vxorps %ymm0,%ymm1,%ymm0",
                "vpsrad $0x1,%xmm0,%xmm1",
                "vextractf128 $0x1,%ymm0,%xmm0",
                "vpsrad $0x1,%xmm0,%xmm0",
                "vextractf128 $0x1,%ymm2,%xmm3",
                "vpaddd %xmm3,%xmm0,%xmm0",
                "vpaddd %xmm2,%xmm1,%xmm1",
                "vinsertf128 $0x1,%xmm0,%ymm1,%ymm0"
            ]
        }
    ]
}